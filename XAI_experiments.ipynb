{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11781057,"sourceType":"datasetVersion","datasetId":7396450},{"sourceId":11795660,"sourceType":"datasetVersion","datasetId":7407082}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ultralytics lime\n# !pip install ttach","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:38:54.026233Z","iopub.execute_input":"2025-05-22T13:38:54.026973Z","iopub.status.idle":"2025-05-22T13:40:06.957284Z","shell.execute_reply.started":"2025-05-22T13:38:54.026947Z","shell.execute_reply":"2025-05-22T13:40:06.956179Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/rigvedrs/YOLO-V11-CAM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T12:03:11.165516Z","iopub.execute_input":"2025-05-13T12:03:11.166120Z","iopub.status.idle":"2025-05-13T12:03:13.725048Z","shell.execute_reply.started":"2025-05-13T12:03:11.166089Z","shell.execute_reply":"2025-05-13T12:03:13.724356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!cp -r /kaggle/working/YOLO-V11-CAM/yolo_cam  /kaggle/working","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T12:03:38.490852Z","iopub.execute_input":"2025-05-13T12:03:38.491626Z","iopub.status.idle":"2025-05-13T12:03:38.612714Z","shell.execute_reply.started":"2025-05-13T12:03:38.491596Z","shell.execute_reply":"2025-05-13T12:03:38.611953Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from yolo_cam.eigen_cam import EigenCAM\nfrom yolo_cam.utils.image import show_cam_on_image, scale_cam_image\nfrom ultralytics import YOLO\n\nmodel = YOLO(\"/kaggle/input/detract-yolo11s/kaggle/working/runs/detect/train/weights/best.pt\")\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimg = cv2.imread('/kaggle/input/test-images/test_images/MVI_40863_img00081.jpg')  # або .png\n#img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\nresults = model(img)\n\nannotated_img = results[0].plot()\n#print(results)\nplt.imshow(annotated_img)\nplt.axis('off')\nplt.show()\n\nimg = cv2.imread('/kaggle/input/test-images/test_images/MVI_40863_img00081.jpg')\nimg = cv2.resize(img, (640, 640))\nrgb_img = img.copy()\nimg = np.float32(img) / 255\n\ntarget_layers =[model.model.model[-2]]\ncam = EigenCAM(model, target_layers,task='od')\ngrayscale_cam = cam(rgb_img)[0, :, :]\ncam_image = show_cam_on_image(img, grayscale_cam, use_rgb=True)\nplt.imshow(cam_image)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T12:17:52.478948Z","iopub.execute_input":"2025-05-13T12:17:52.479464Z","iopub.status.idle":"2025-05-13T12:17:53.214826Z","shell.execute_reply.started":"2025-05-13T12:17:52.479440Z","shell.execute_reply":"2025-05-13T12:17:53.214097Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install lime","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-13T12:08:52.717554Z","iopub.execute_input":"2025-05-13T12:08:52.718178Z","iopub.status.idle":"2025-05-13T12:08:55.835277Z","shell.execute_reply.started":"2025-05-13T12:08:52.718152Z","shell.execute_reply":"2025-05-13T12:08:55.834545Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nfrom ultralytics import YOLO\nfrom lime import lime_image\nfrom skimage.segmentation import mark_boundaries\nimport matplotlib.pyplot as plt\nfrom IPython.display import display, Image\n\ndef explain_yolo11_top3(image_path, model_path=\"/kaggle/input/detract-yolo11s/kaggle/working/runs/detect/train/weights/best.pt\", num_samples=100, top_n=3):\n    model = YOLO(model_path)\n    image = cv2.imread(image_path)\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    results = model(image_rgb)[0]\n    detections = results.boxes.data.cpu().numpy()\n\n    detections = detections[detections[:, 4].argsort()[::-1]]  # sort by confidence\n    detections = detections[:top_n]\n\n    explainer = lime_image.LimeImageExplainer()\n\n    for idx, det in enumerate(detections):\n        x1, y1, x2, y2, conf, cls = det.astype(int)\n        label = model.names[int(cls)]\n\n        crop_img = image_rgb[y1:y2, x1:x2]\n\n        def yolo_predict(images):\n            preds = []\n            for img in images:\n                img_bgr = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n                result = model(img_bgr, verbose=False)[0]\n                boxes = result.boxes.data.cpu().numpy()\n                cls_scores = np.zeros(len(model.names))\n                for box in boxes:\n                    if int(box[5]) == int(cls) and box[4] > 0.5:\n                        cls_scores[int(cls)] = box[4]\n                preds.append(cls_scores)\n            return np.array(preds)\n\n        explanation = explainer.explain_instance(\n            image_rgb,\n            yolo_predict,\n            top_labels=1,\n            hide_color=0,\n            num_samples=num_samples\n        )\n\n        temp, mask = explanation.get_image_and_mask(\n            explanation.top_labels[0],\n            positive_only=True,\n            num_features=5,\n            hide_rest=False\n        )\n\n        # === Маленька фігура для crop-об’єкта ===\n        plt.figure(figsize=(5, 5))\n        plt.imshow(crop_img)\n        plt.title(f'Detected Object: {label}', fontsize=14)\n        plt.axis('off')\n        plt.tight_layout()\n        plt.show()\n\n        plt.figure(figsize=(12, 12), dpi=150)\n        plt.imshow(mark_boundaries(image_rgb, mask))\n        plt.title(f'LIME Explanation: {label}', fontsize=18)\n        plt.axis('off')\n\n        plt.tight_layout()\n        #plt.savefig(f'lime_expl_{idx}.png', dpi=300)\n        plt.show()\n\nif __name__ == \"__main__\":\n    image_path = \"/kaggle/input/test-images/test_images/MVI_40901_img00752.jpg\" \n    explain_yolo11_top3(image_path, num_samples=100)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:40:14.727223Z","iopub.execute_input":"2025-05-22T13:40:14.727964Z","iopub.status.idle":"2025-05-22T13:41:12.293817Z","shell.execute_reply.started":"2025-05-22T13:40:14.727937Z","shell.execute_reply":"2025-05-22T13:41:12.292851Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/test-images/test_images/MVI_40901_img00752.jpg\"\nexplain_yolo11_top3(image_path, num_samples=300)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:41:12.294946Z","iopub.execute_input":"2025-05-22T13:41:12.295292Z","iopub.status.idle":"2025-05-22T13:42:45.244242Z","shell.execute_reply.started":"2025-05-22T13:41:12.295273Z","shell.execute_reply":"2025-05-22T13:42:45.243393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/test-images/test_images/MVI_40901_img00752.jpg\"\nexplain_yolo11_top3(image_path, num_samples=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:42:45.245104Z","iopub.execute_input":"2025-05-22T13:42:45.245332Z","iopub.status.idle":"2025-05-22T13:45:05.423501Z","shell.execute_reply.started":"2025-05-22T13:42:45.245313Z","shell.execute_reply":"2025-05-22T13:45:05.422506Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/test-images/test_images/MVI_40901_img00752.jpg\"\nexplain_yolo11_top3(image_path, num_samples=1000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:45:05.424870Z","iopub.execute_input":"2025-05-22T13:45:05.425113Z","iopub.status.idle":"2025-05-22T13:49:25.551941Z","shell.execute_reply.started":"2025-05-22T13:45:05.425093Z","shell.execute_reply":"2025-05-22T13:49:25.551178Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/test-images/test_images/MVI_40901_img00752.jpg\"\nexplain_yolo11_top3(image_path, num_samples=1500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:49:25.552812Z","iopub.execute_input":"2025-05-22T13:49:25.553085Z","iopub.status.idle":"2025-05-22T13:55:47.901423Z","shell.execute_reply.started":"2025-05-22T13:49:25.553062Z","shell.execute_reply":"2025-05-22T13:55:47.900342Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"image_path = \"/kaggle/input/test-images/test_images/MVI_40901_img00752.jpg\"\nexplain_yolo11_top3(image_path, num_samples=2000)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-22T13:55:47.902338Z","iopub.execute_input":"2025-05-22T13:55:47.902597Z","iopub.status.idle":"2025-05-22T14:04:09.516943Z","shell.execute_reply.started":"2025-05-22T13:55:47.902571Z","shell.execute_reply":"2025-05-22T14:04:09.515985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport shap\nfrom ultralytics import YOLO\nfrom PIL import Image\n\n\ndef explain_yolo11_detections(image_path, model, top_k=3, shap_samples=50):\n    img = cv2.imread(image_path)\n    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img_pil = Image.fromarray(img_rgb)\n\n    results = model(img_rgb, verbose=False)\n\n    boxes = results[0].boxes.xyxy.cpu().numpy()  # Координати bounding boxes\n    scores = results[0].boxes.conf.cpu().numpy()  # Впевненість\n    classes = results[0].boxes.cls.cpu().numpy()  # Класи\n    class_names = results[0].names  # Назви класів\n\n    top_indices = np.argsort(scores)[::-1][:top_k]\n\n    for idx in top_indices:\n        class_id = int(classes[idx])\n        class_name = class_names[class_id]\n        score = scores[idx]\n        box = boxes[idx]\n\n        def model_predict(images, target_box=box, target_class_id=class_id):\n            predictions = []\n            for img in images:\n                img = img.transpose((1, 2, 0))  \n                img = img.astype(np.uint8)\n                result = model(img, verbose=False)\n                detected_boxes = result[0].boxes.xyxy.cpu().numpy()\n                conf = result[0].boxes.conf.cpu().numpy()\n                cls = result[0].boxes.cls.cpu().numpy()\n\n                best_iou = 0\n                best_conf = 0\n                for i, (det_box, det_conf, det_cls) in enumerate(zip(detected_boxes, conf, cls)):\n                    if int(det_cls) != target_class_id:\n                        continue\n                    x1 = max(target_box[0], det_box[0])\n                    y1 = max(target_box[1], det_box[1])\n                    x2 = min(target_box[2], det_box[2])\n                    y2 = min(target_box[3], det_box[3])\n                    intersection = max(0, x2 - x1) * max(0, y2 - y1)\n                    area1 = (target_box[2] - target_box[0]) * (target_box[3] - target_box[1])\n                    area2 = (det_box[2] - det_box[0]) * (det_box[3] - det_box[1])\n                    union = area1 + area2 - intersection\n                    iou = intersection / union if union > 0 else 0\n                    if iou > best_iou:\n                        best_iou = iou\n                        best_conf = det_conf\n                predictions.append([best_conf]) \n            return np.array(predictions)\n\n        masker = shap.maskers.Image(\"inpaint_telea\", img_rgb.shape)\n\n        explainer = shap.Explainer(model_predict, masker)\n\n        img_shap = img_rgb.transpose((2, 0, 1))  \n        img_shap = img_shap[np.newaxis, ...]  \n\n        shap_values = explainer(img_shap, max_evals=shap_samples)\n\n        print(\"SHAP values shape:\", shap_values.shape)\n\n        shap_vals = shap_values.values[0, ..., 0]  \n        shap_vals = np.transpose(shap_vals, (1, 2, 0)) \n        print(\"Adjusted SHAP values shape:\", shap_vals.shape)\n\n        shap.image_plot(shap_vals, pixel_values=img_rgb, labels=[class_name], show=False)\n        #plt.savefig(f'/kaggle/working/test{idx}_{shap_samples}.png', dpi=150)       \n        \nmodel = YOLO(\"/kaggle/input/detract-yolo11s/kaggle/working/runs/detect/train/weights/best.pt\")\n\nimage_path = \"/kaggle/input/test-images/test_images/MVI_40901_img00752.jpg\" \nexplain_yolo11_detections(image_path, model, top_k=3, shap_samples=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T09:45:43.694873Z","iopub.execute_input":"2025-05-14T09:45:43.695178Z","iopub.status.idle":"2025-05-14T09:46:51.137385Z","shell.execute_reply.started":"2025-05-14T09:45:43.695156Z","shell.execute_reply":"2025-05-14T09:46:51.136589Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explain_yolo11_detections(image_path, model, top_k=3, shap_samples=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T09:44:37.062871Z","iopub.status.idle":"2025-05-14T09:44:37.063186Z","shell.execute_reply.started":"2025-05-14T09:44:37.063009Z","shell.execute_reply":"2025-05-14T09:44:37.063021Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explain_yolo11_detections(image_path, model, top_k=3, shap_samples=1000)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-14T10:21:21.444Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explain_yolo11_detections(image_path, model, top_k=3, shap_samples=150)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T09:46:51.138835Z","iopub.execute_input":"2025-05-14T09:46:51.139277Z","iopub.status.idle":"2025-05-14T09:48:51.419529Z","shell.execute_reply.started":"2025-05-14T09:46:51.139258Z","shell.execute_reply":"2025-05-14T09:48:51.418782Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explain_yolo11_detections(image_path, model, top_k=3, shap_samples=300)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T09:48:51.420395Z","iopub.execute_input":"2025-05-14T09:48:51.420647Z","iopub.status.idle":"2025-05-14T09:52:09.898527Z","shell.execute_reply.started":"2025-05-14T09:48:51.420619Z","shell.execute_reply":"2025-05-14T09:52:09.897784Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"explain_yolo11_detections(image_path, model, top_k=3, shap_samples=500)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-14T09:52:09.900181Z","iopub.execute_input":"2025-05-14T09:52:09.900432Z","iopub.status.idle":"2025-05-14T09:57:12.205991Z","shell.execute_reply.started":"2025-05-14T09:52:09.900416Z","shell.execute_reply":"2025-05-14T09:57:12.205251Z"}},"outputs":[],"execution_count":null}]}